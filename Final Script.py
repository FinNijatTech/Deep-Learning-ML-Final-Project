# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14I37T9tfEf5G99eP16PxgxrF6Vg6ac-n
"""

import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as yf
from sklearn.metrics import (
    accuracy_score, mean_squared_error, precision_score, recall_score,
    f1_score, confusion_matrix, mean_absolute_percentage_error, r2_score
)
from collections import defaultdict
from sklearn.linear_model import LinearRegression
import statsmodels.api as sm
import seaborn as sns
import pandas_datareader.data as web
from sklearn.ensemble import GradientBoostingClassifier
from datetime import datetime
from sklearn.model_selection import train_test_split
import tensorflow as tf

import warnings
warnings.filterwarnings('ignore')

SP500 = yf.download("^GSPC", start="1970-01-01", end="2024-01-01")

SP500 = SP500.reset_index()

"""**Exploratory Data Analysis**"""

SP500.head()

SP500.info()

# Change Dtype of Date column
SP500["Date"] = pd.to_datetime(SP500["Date"])

plt.figure(figsize=(10, 8))
plt.plot(SP500["Date"], SP500["Adj Close"])
plt.title('S&P 500')
plt.ylabel('Adj Close')

# Now lets plot the total volume of stock being traded each day
plt.figure(figsize=(10, 8))
plt.plot(SP500["Date"], SP500["Volume"])
plt.title('SP500')
plt.ylabel('Volume')

"""What was the daily return of the index on average ?"""

SP500["Daily Return"] = SP500["Adj Close"].pct_change()

plt.figure(figsize=(10, 8))
plt.plot(SP500["Date"], SP500["Daily Return"])
plt.title("S&P 500")
plt.ylabel('Daily Return')

plt.figure(figsize=(10, 8))
sns.distplot(SP500["Daily Return"].dropna(), color = "purple")
plt.title("S&P 500")

print("Kurtosis Value")
print(f"S&P500: {SP500['Daily Return'].kurtosis()}")

SP500_returns = pd.DataFrame()
SP500_returns["S&P500"] = SP500["Adj Close"]
SP_500_returns = SP500_returns.pct_change()
SP_500_returns.head()

SP500.set_index('Date', inplace=True)

SP500

# Calculate 50-day and 200-day moving averages
SP500["SMA_50"] = SP500["Close"].rolling(window=50).mean()
SP500["SMA_200"] = SP500["Close"].rolling(window=200).mean()

# Calculate the RSI (Relative Strength Index) for a 14-day period
rsi_period = 14
delta = SP500["Adj Close"].diff(1)
gain = delta.where(delta > 0, 0)
loss = -delta.where(delta < 0, 0)
average_gain = gain.rolling(window=rsi_period).mean()
average_loss = loss.rolling(window=rsi_period).mean()
relative_strength = average_gain / average_loss
rsi = 100 - (100 / (1 + relative_strength))
SP500["RSI"] = rsi

# Display the data
print(SP500.tail())

# Plot the closing price, moving averages, and RSI
plt.figure(figsize=(12, 6))
plt.plot(SP500.index, SP500["Adj Close"], label="S&P 500 Adj Close", color='blue')
plt.plot(SP500.index, SP500["SMA_50"], label="50-day SMA", color='orange')
plt.plot(SP500.index, SP500["SMA_200"], label="200-day SMA", color='red')
plt.legend()
plt.title("S&P 500 Historical Data with Moving Averages")
plt.xlabel("Date")
plt.ylabel("Price")
plt.grid(True)

plt.figure(figsize=(12, 3))
plt.plot(SP500.index, SP500["RSI"], label="RSI", color='green')
plt.axhline(70, color='red', linestyle='--', alpha=0.5)
plt.axhline(30, color='green', linestyle='--', alpha=0.5)
plt.fill_between(SP500.index, 30, 70, alpha=0.2, color='yellow')
plt.legend()
plt.title("Relative Strength Index (RSI)")
plt.xlabel("Date")
plt.ylabel("RSI Value")
plt.grid(True)

plt.show()

df = SP500[['Adj Close', 'SMA_50', 'SMA_200', 'RSI']]

df.dropna(inplace=True)

df

df

df = df.astype(int)

# x = df[['Daily Return', 'SMA_50', 'SMA_200', 'RSI']]
# y = df['Adj Close']

# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

df.reset_index(inplace=True)

df['Date'] = pd.to_datetime(df['Date'])

# Split data into training (1990-01-01 to 2019-12-31) and test (2020-01-01 to 2022-01-01) sets
train_data = df[(df['Date'] >= '1970-01-01') & (df['Date'] <= '2023-06-30')]
test_data = df[(df['Date'] >= '2023-07-01') & (df['Date'] <= '2024-01-01')]

x_train = train_data[['RSI', 'SMA_50', 'SMA_200']]
y_train = train_data['Adj Close']

x_test = test_data[['RSI', 'SMA_50', 'SMA_200']]
y_test =  test_data['Adj Close']

"""**Linear Regression**"""

# Create DataFrames for predictions and actual values

# Step 1: Train the linear regression model on the training data
X_train_with_const = sm.add_constant(x_train)  # Add a constant term for the intercept
model = sm.OLS(y_train, X_train_with_const).fit()

# Step 2: Calculate predicted values on the testing data
X_test_with_const = sm.add_constant(x_test)  # Add a constant term for the intercept
prediction_lr = model.predict(X_test_with_const)
prediction_lr = pd.DataFrame({'Date': test_data['Date'], 'Predicted_Price': prediction_lr})
y_test_lr = pd.DataFrame({'Date': test_data['Date'], 'Actual_Price': y_test})

# Merge the two DataFrames on 'Date'
merged_df = pd.merge(prediction_lr, y_test_lr, on='Date')

# Plot the two time series data
plt.figure(figsize=(12, 6))
plt.plot(merged_df['Date'], merged_df['Predicted_Price'], label='Predicted Price', color='blue')
plt.plot(merged_df['Date'], merged_df['Actual_Price'], label='Actual Price', color='green')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Linear Regression Model Forecast vs. Actual')
plt.legend()
plt.grid(True)
plt.show()

import statsmodels.api as sm

# Step 1: Train the linear regression model on the training data
X_train_with_const = sm.add_constant(x_train)  # Add a constant term for the intercept
model = sm.OLS(y_train, X_train_with_const).fit()

# Get the intercept and coefficients
intercept = model.params['const']
coefficients = model.params.drop('const')  # Drop the intercept term

# Get the p-values for intercept and coefficients
p_values_intercept = model.pvalues['const']
p_values_coefficients = model.pvalues.drop('const')  # Drop the intercept term

# Display the equation
print(f"Linear Regression Equation: y = {intercept:.4f}", end=" ")
for feature, coefficient in coefficients.items():
    print(f"+ ({coefficient:.4f} * {feature})", end=" ")

# Display p-values
print("\n\nP-values:")
print(f"Intercept (const): {p_values_intercept:.4f}")
for feature, p_value in p_values_coefficients.items():
    print(f"{feature}: {p_value:.4f}")

"""**KNN**"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# from sklearn.model_selection import GridSearchCV
# from sklearn.neighbors import KNeighborsClassifier
# 
# knn = KNeighborsClassifier()
# 
# param_grid = {
#     'n_neighbors': [3, 5, 7, 9],
#     'weights': ['uniform', 'distance'],
#     'p': [1, 2]
# }
# 
# knn_grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')
# 
# knn_grid.fit(x_train, y_train)
# 
# best_knn_params = knn_grid.best_params_
# best_knn_score = knn_grid.best_score_
# 
# print("Best hyperparameters for KNN:", best_knn_params)

knn = KNeighborsClassifier(n_neighbors= 3, p= 1, weights='distance')
knn.fit(x_train, y_train)
prediction_knn = knn.predict(x_test)

# Create DataFrames for predictions and actual values
prediction_df = pd.DataFrame({'Date': test_data['Date'], 'Predicted_Price': prediction_knn})
y_test_df = pd.DataFrame({'Date': test_data['Date'], 'Actual_Price': y_test})

# Merge the two DataFrames on 'Date'
merged_df = pd.merge(prediction_df, y_test_df, on='Date')

# Plot the two time series data
plt.figure(figsize=(12, 6))
plt.plot(merged_df['Date'], merged_df['Predicted_Price'], label='Predicted Price', color='blue')
plt.plot(merged_df['Date'], merged_df['Actual_Price'], label='Actual Price', color='green')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('KNN Model Forecast vs. Actual')
plt.legend()
plt.grid(True)
plt.show()

"""**LSTM**"""

SP500 = yf.download("^GSPC", start="1970-01-01", end="2024-01-01")

SP500 = SP500.reset_index()

SP500

def Dataset(Data, Date):

  Train_Data = Data['Adj Close'][Data['Date'] < Date].to_numpy()
  Data_Train = []
  Data_Train_X = []
  Data_Train_Y = []
  for i in range(0, len(Train_Data), 5):
    try:
      Data_Train.append(Train_Data[i : i + 5])
    except:
      pass

  if len(Data_Train[-1]) < 5:
    Data_Train.pop(-1)

  Data_Train_X = Data_Train[0 : -1]
  Data_Train_X = np.array(Data_Train_X)
  Data_Train_X = Data_Train_X.reshape((-1, 5, 1))
  Data_Train_Y = Data_Train[1 : len(Data_Train)]
  Data_Train_Y = np.array(Data_Train_Y)
  Data_Train_Y = Data_Train_Y.reshape((-1, 5, 1))


  Test_Data = Data['Adj Close'][Data['Date'] >= Date].to_numpy()
  Data_Test = []
  Data_Test_X = []
  Data_Test_Y = []
  for i in range(0, len(Test_Data), 5):
    try:
      Data_Test.append(Test_Data[i : i + 5])
    except:
      pass

  if len(Data_Test[-1]) < 5:
    Data_Test.pop(-1)

  Data_Test_X = Data_Test[0 : -1]
  Data_Test_X = np.array(Data_Test_X)
  Data_Test_X = Data_Test_X.reshape((-1, 5, 1))
  Data_Test_Y = Data_Test[1 : len(Data_Test)]
  Data_Test_Y = np.array(Data_Test_Y)
  Data_Test_Y = Data_Test_Y.reshape((-1, 5, 1))

  return Data_Train_X, Data_Train_Y, Data_Test_X, Data_Test_Y

def Model():
  model = tf.keras.models.Sequential([
                                      tf.keras.layers.LSTM(200, input_shape = (5, 1), activation = tf.nn.leaky_relu, return_sequences = True),
                                      tf.keras.layers.LSTM(200, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(200, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(100, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(50, activation = tf.nn.leaky_relu),
                                      tf.keras.layers.Dense(5, activation = tf.nn.leaky_relu)
                                      ])
  return model

model = Model()

tf.keras.utils.plot_model(model, show_shapes=True)

model.summary()

def scheduler(epoch):

  if epoch <= 150:
    lrate = (10 ** -5) * (epoch / 150)
  elif epoch <= 400:
    initial_lrate = (10 ** -5)
    k = 0.01
    lrate = initial_lrate * math.exp(-k * (epoch - 150))
  else:
    lrate = (10 ** -6)

  return lrate

epochs = [i for i in range(1, 1001, 1)]
lrate = [scheduler(i) for i in range(1, 1001, 1)]
plt.plot(epochs, lrate)

callback = tf.keras.callbacks.LearningRateScheduler(scheduler)

SP500["Date"] = pd.to_datetime(SP500["Date"])

SP500

SP500_Date = '2023-06-01'
SP500_Train_X, SP500_Train_Y, SP500_Test_X, SP500_Test_Y = Dataset(SP500, SP500_Date)

SP500_Model = Model()
SP500_Model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mse', metrics = tf.keras.metrics.RootMeanSquaredError())
SP500_hist = SP500_Model.fit(SP500_Train_X, SP500_Train_Y, epochs = 260, validation_data = (SP500_Test_X, SP500_Test_Y), callbacks=[callback])

history_dict = SP500_hist.history

loss = history_dict["loss"]
root_mean_squared_error = history_dict["root_mean_squared_error"]
val_loss = history_dict["val_loss"]
val_root_mean_squared_error = history_dict["val_root_mean_squared_error"]

epochs = range(1, len(loss) + 1)

fig, (ax1, ax2) = plt.subplots(1, 2)

fig.set_figheight(5)
fig.set_figwidth(15)

ax1.plot(epochs, loss, label = 'Training Loss')
ax1.plot(epochs, val_loss, label = 'Validation Loss')
ax1.set(xlabel = "Epochs", ylabel = "Loss")
ax1.legend()

ax2.plot(epochs, root_mean_squared_error, label = "Training Root Mean Squared Error")
ax2.plot(epochs, val_root_mean_squared_error, label = "Validation Root Mean Squared Error")
ax2.set(xlabel = "Epochs", ylabel = "Loss")
ax2.legend()

plt.show()

SP500_prediction = SP500_Model.predict(SP500_Test_X)

prediction_df = pd.DataFrame({
    'Date': SP500['Date'][SP500['Date'] >= '2023-06-13'][:-1],
    'Predicted_Price': SP500_prediction.reshape(-1)[:-2]
})
actual_df = pd.DataFrame({
    'Date': SP500['Date'][SP500['Date'] >= '2023-06-13'],
    'Actual_Price': SP500['Adj Close'][SP500['Date'] >= '2023-06-13']
})

# Merge the two DataFrames on 'Date'
merged_df = pd.merge(prediction_df, actual_df, on='Date')

# Plot the two time series data
plt.figure(figsize=(12, 6))
plt.plot(merged_df['Date'], merged_df['Predicted_Price'], label='Predicted Price', color='blue')
plt.plot(merged_df['Date'], merged_df['Actual_Price'], label='Actual Price', color='green')
plt.xlabel('Date')
plt.ylabel('Price')
plt.title('LSTM Model Forecast vs. Actual')
plt.legend()
plt.grid(True)
plt.show()

